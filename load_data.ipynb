{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe07340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "import networkx as nx\n",
    "import random\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial import distance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "from networkx.algorithms.community.quality import modularity\n",
    "\n",
    "from functions import calculate_monthly_velocities_cosine, get_similarities, get_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319313de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Parquet file into an Arrow Table\n",
    "tweets = pq.read_table('data/tweets_light.parquet')\n",
    "retweets = pq.read_table('data/retweets_light.parquet')\n",
    "users = pq.read_table('data/users_tw+rt_light.parquet')\n",
    "\n",
    "# Convert the Arrow Table to a Pandas DataFrame\n",
    "df_tweets = tweets.to_pandas()\n",
    "df_retweets = retweets.to_pandas()\n",
    "df_users = users.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782475dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert column data types\n",
    "df_tweets['author_id'] = df_tweets['author_id'].astype(int)\n",
    "df_users['id'] = df_users['id'].astype(float)\n",
    "\n",
    "#merge df_tweets and df_users\n",
    "df_users_tweets = pd.merge(df_tweets, df_users, left_on=\"author_id\", right_on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_tweets.drop(columns=\"id_y\", inplace = True)\n",
    "df_users_tweets = df_users_tweets.rename(columns={\"created_at_x\":\"tweet_created_at\", \"id_x\":\"original_post_id\", \"created_at_y\":\"account_created_at\", \"name\":\"author_name\", \"username\":\"author_username\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge df_user_tweets and df_retweets on original_post_id and post_id\n",
    "df_all = pd.merge(df_users_tweets, df_retweets, left_on=\"original_post_id\", right_on=\"post_id\")\n",
    "df_all.drop(columns=[\"post_id\", \"url\", \"location\", \"verified\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert column data types\n",
    "df_all['original_post_id'] = df_all['original_post_id'].astype(int)\n",
    "df_all['retweeter_id'] = df_all['retweeter_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop(columns=['lang', 'text',\n",
    "       'possibly_sensitive', 'referenced_id', 'reference_type',\n",
    "       'public_metrics.like_count', 'public_metrics.quote_count',\n",
    "       'public_metrics.reply_count', 'public_metrics.retweet_count',\n",
    "       'account_created_at', 'description','name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826dbc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7089c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>original_post_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>retweeter_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29235029</td>\n",
       "      <td>2.923503e+07</td>\n",
       "      <td>2.923503e+07</td>\n",
       "      <td>2.923503e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2020-06-25 17:59:32.733049</td>\n",
       "      <td>1.276245e+18</td>\n",
       "      <td>1.185610e+17</td>\n",
       "      <td>4.458498e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2017-12-31 23:11:09</td>\n",
       "      <td>9.476212e+17</td>\n",
       "      <td>5.893702e+06</td>\n",
       "      <td>1.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019-03-09 14:13:47</td>\n",
       "      <td>1.104400e+18</td>\n",
       "      <td>1.406026e+07</td>\n",
       "      <td>5.754239e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020-06-02 07:19:34</td>\n",
       "      <td>1.267752e+18</td>\n",
       "      <td>1.507257e+08</td>\n",
       "      <td>2.895642e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021-09-21 22:00:00</td>\n",
       "      <td>1.440548e+18</td>\n",
       "      <td>1.024976e+09</td>\n",
       "      <td>9.851892e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2022-12-31 22:19:02</td>\n",
       "      <td>1.609328e+18</td>\n",
       "      <td>1.555225e+18</td>\n",
       "      <td>1.666974e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.928046e+17</td>\n",
       "      <td>3.106293e+17</td>\n",
       "      <td>5.506337e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_created_at  original_post_id     author_id  \\\n",
       "count                    29235029      2.923503e+07  2.923503e+07   \n",
       "mean   2020-06-25 17:59:32.733049      1.276245e+18  1.185610e+17   \n",
       "min           2017-12-31 23:11:09      9.476212e+17  5.893702e+06   \n",
       "25%           2019-03-09 14:13:47      1.104400e+18  1.406026e+07   \n",
       "50%           2020-06-02 07:19:34      1.267752e+18  1.507257e+08   \n",
       "75%           2021-09-21 22:00:00      1.440548e+18  1.024976e+09   \n",
       "max           2022-12-31 22:19:02      1.609328e+18  1.555225e+18   \n",
       "std                           NaN      1.928046e+17  3.106293e+17   \n",
       "\n",
       "       retweeter_id  \n",
       "count  2.923503e+07  \n",
       "mean   4.458498e+17  \n",
       "min    1.200000e+01  \n",
       "25%    5.754239e+08  \n",
       "50%    2.895642e+09  \n",
       "75%    9.851892e+17  \n",
       "max    1.666974e+18  \n",
       "std    5.506337e+17  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49884d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df has shape: (29235029, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"df has shape:\",df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939563c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>original_post_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>author_username</th>\n",
       "      <th>retweeter_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 22:46:18</td>\n",
       "      <td>1079886497279561728</td>\n",
       "      <td>622354597</td>\n",
       "      <td>Salvo Di Grazia</td>\n",
       "      <td>MedBunker</td>\n",
       "      <td>951848540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 22:46:18</td>\n",
       "      <td>1079886497279561728</td>\n",
       "      <td>622354597</td>\n",
       "      <td>Salvo Di Grazia</td>\n",
       "      <td>MedBunker</td>\n",
       "      <td>135554444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 22:46:18</td>\n",
       "      <td>1079886497279561728</td>\n",
       "      <td>622354597</td>\n",
       "      <td>Salvo Di Grazia</td>\n",
       "      <td>MedBunker</td>\n",
       "      <td>433418060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 22:46:18</td>\n",
       "      <td>1079886497279561728</td>\n",
       "      <td>622354597</td>\n",
       "      <td>Salvo Di Grazia</td>\n",
       "      <td>MedBunker</td>\n",
       "      <td>1668533642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31 22:46:18</td>\n",
       "      <td>1079886497279561728</td>\n",
       "      <td>622354597</td>\n",
       "      <td>Salvo Di Grazia</td>\n",
       "      <td>MedBunker</td>\n",
       "      <td>1623208790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_created_at     original_post_id  author_id      author_name  \\\n",
       "0 2018-12-31 22:46:18  1079886497279561728  622354597  Salvo Di Grazia   \n",
       "1 2018-12-31 22:46:18  1079886497279561728  622354597  Salvo Di Grazia   \n",
       "2 2018-12-31 22:46:18  1079886497279561728  622354597  Salvo Di Grazia   \n",
       "3 2018-12-31 22:46:18  1079886497279561728  622354597  Salvo Di Grazia   \n",
       "4 2018-12-31 22:46:18  1079886497279561728  622354597  Salvo Di Grazia   \n",
       "\n",
       "  author_username  retweeter_id  \n",
       "0       MedBunker     951848540  \n",
       "1       MedBunker     135554444  \n",
       "2       MedBunker     433418060  \n",
       "3       MedBunker    1668533642  \n",
       "4       MedBunker    1623208790  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1f9219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading df from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"data/df_checkpoint.parquet\"\n",
    "\n",
    "# load data from checkpoint or save\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Loading df from checkpoint...\")\n",
    "    df_all = pd.read_parquet(checkpoint_path)\n",
    "else:\n",
    "    print(\"Saving df to checkpoint...\")\n",
    "    df_all.to_parquet(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a8a4d",
   "metadata": {},
   "source": [
    "### Get Statistcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7aa32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df_all[\"tweet_created_at\"].dt.year.unique()\n",
    "years = [y for y in years if y != 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a8c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_mapping = {\n",
    "    1: \"January\",\n",
    "    2: \"February\",\n",
    "    3: \"March\",\n",
    "    4: \"April\",\n",
    "    5: \"May\",\n",
    "    6: \"June\",\n",
    "    7: \"July\",\n",
    "    8: \"August\",\n",
    "    9: \"September\",\n",
    "    10: \"October\",\n",
    "    11: \"November\",\n",
    "    12: \"December\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2209868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(month_num:int, year:int):\n",
    "    '''\n",
    "    get 1 month of data from df (all data)\n",
    "    '''\n",
    "    return df[df['tweet_created_at'].dt.to_period('M') == f'{year}-{month_num}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4b56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def author_mapping(month_name:str):\n",
    "\n",
    "        '''\n",
    "        This function outputs the top and bottom 10 similarities for a specific month.\n",
    "        '''\n",
    "        author_to_index = {author: j for j, author in enumerate(month_data[month_name]['author_id'].unique())}\n",
    "\n",
    "        ## Create a mapping from author_id to author_name\n",
    "        author_id_to_name = month_data[month_name].set_index('author_id')['author_name'].to_dict()\n",
    "\n",
    "        #  Map author IDs to names\n",
    "        author_names = [author_id_to_name[author] for author in author_to_index.keys()]\n",
    "\n",
    "        # Create a DataFrame for the similarities matrix\n",
    "        similarities_df = similarities_copy[month_name]\n",
    "        similarities_df.columns = author_names\n",
    "        similarities_df.index = author_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aba0d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarities for 2018: 100%|██████████| 12/12 [01:13<00:00,  6.12s/it]\n",
      "Calculating similarities for 2019: 100%|██████████| 12/12 [00:40<00:00,  3.35s/it]\n",
      "Calculating similarities for 2020: 100%|██████████| 12/12 [00:54<00:00,  4.55s/it]\n",
      "Calculating similarities for 2021: 100%|██████████| 12/12 [00:45<00:00,  3.83s/it]\n",
      "Calculating similarities for 2022: 100%|██████████| 12/12 [00:45<00:00,  3.77s/it]\n"
     ]
    }
   ],
   "source": [
    "year_stats = {}\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    # create a filtered dataframe for the current year\n",
    "    df = df_all[df_all[\"tweet_created_at\"].dt.year == year]\n",
    "    \n",
    "    month_data = {}\n",
    "\n",
    "    for k, v in month_mapping.items():\n",
    "        month_data[v] = get_month(month_num=k, year=year)\n",
    "\n",
    "    month_matrices = {}\n",
    "\n",
    "    for k, v in month_data.items():\n",
    "        month_matrices[k] = get_matrix(month_data[k])\n",
    "\n",
    "    similarities = {}\n",
    "\n",
    "    for k, v in tqdm(month_matrices.items(), desc=f\"Calculating similarities for {year}\"):\n",
    "        similarities[k] = get_similarities(month_matrix=month_matrices[k], metric='cosine')\n",
    "    \n",
    "    similarities_copy = similarities.copy()\n",
    "\n",
    "    # map author names to rows and columns\n",
    "    for month in similarities_copy.keys():\n",
    "        author_mapping(month_name=month)\n",
    "\n",
    "    # merge similarities using full outer join\n",
    "    merged_similarities = pd.DataFrame()\n",
    "\n",
    "    for month, similarity_df in similarities_copy.items():\n",
    "        similarity_df.columns = [f\"{col}_{month}\" for col in similarity_df.columns]\n",
    "        merged_similarities = pd.merge(\n",
    "            merged_similarities, similarity_df, how=\"outer\", left_index=True, right_index=True).fillna(0) # Add suffix manually to avoid collision\n",
    "            \n",
    "    merged_similarities = merged_similarities.T\n",
    "\n",
    "    month_names = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "    avg_std_per_month = {}\n",
    "    avg_mean_per_month = {}\n",
    "\n",
    "    for month in month_names:\n",
    "        filtered = merged_similarities[merged_similarities.index.str.contains(f'_{month}', case=False)].sort_index()\n",
    "        std_per_column = filtered.std(axis=0, skipna=True)\n",
    "        mean_per_column = filtered.mean(axis=0, skipna=True)\n",
    "        avg_std_per_month[month] = std_per_column.mean()\n",
    "        avg_mean_per_month[month] = mean_per_column.mean()\n",
    "\n",
    "    # Calculate velocities using cosine distance\n",
    "    velocities_cosine_full = calculate_monthly_velocities_cosine(merged_similarities, month_names)\n",
    "\n",
    "    # Convert the velocities_cosine dictionary into a DataFrame\n",
    "    velocities_df_full = pd.concat(velocities_cosine_full, axis=0)\n",
    "\n",
    "    # Reset the index to make the month pairs a column\n",
    "    velocities_df_full.reset_index(inplace=True)\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    velocities_df_full.columns = ['Month Pair', 'Node', 'Velocity']\n",
    "\n",
    "    # Define the desired column order\n",
    "    column_order = [\n",
    "        'January-February', 'February-March', 'March-April', 'April-May', \n",
    "        'May-June', 'June-July', 'July-August', 'August-September', \n",
    "        'September-October', 'October-November', 'November-December'\n",
    "    ]\n",
    "\n",
    "    # Pivot the DataFrame to make month pairs the column names\n",
    "    velocities_df_full = velocities_df_full.pivot(index='Node', columns='Month Pair', values='Velocity')\n",
    "\n",
    "    # Reorder the columns\n",
    "    velocities_df_full = velocities_df_full[column_order]\n",
    "\n",
    "    # Reset the index to make it more readable (optional)\n",
    "    velocities_df_full.reset_index(inplace=False)\n",
    "\n",
    "    # Prepare velocity means and stds for the same x-axis\n",
    "    veloc_means_arr = np.array([velocities_df_full[col].mean(skipna=True) for col in column_order])\n",
    "    veloc_stds_arr = np.array([velocities_df_full[col].std(skipna=True) for col in column_order])\n",
    "\n",
    "    modularity_per_month = {}\n",
    "\n",
    "    for month in month_names:\n",
    "        # Create the graph for the month\n",
    "        filtered = merged_similarities[merged_similarities.index.str.contains(f'_{month}', case=False)].sort_index()\n",
    "        filtered.index = filtered.index.str.replace(r'_[^_]+$', '', regex=True)\n",
    "\n",
    "        filtered = filtered.loc[filtered.index, filtered.index]\n",
    "        G = nx.from_pandas_adjacency(filtered)\n",
    "        \n",
    "        # Louvain communities and modularity\n",
    "        communities = louvain_communities(G, weight='weight', seed=42) # weight='weight' as values from the filtered variable\n",
    "        mod = modularity(G, communities, weight='weight')\n",
    "        modularity_per_month[month] = mod\n",
    "\n",
    "    consecutive_modularity_averages = []\n",
    "    consecutive_month_pairs = []\n",
    "\n",
    "    months = list(modularity_per_month.keys())\n",
    "    modularities = list(modularity_per_month.values())\n",
    "\n",
    "    for i in range(len(months) - 1):\n",
    "        avg = (modularities[i] + modularities[i + 1]) / 2\n",
    "        consecutive_modularity_averages.append(avg)\n",
    "        consecutive_month_pairs.append(f\"{months[i]}-{months[i+1]}\")\n",
    "\n",
    "    # Store stats for this year, now including avg_std_per_month and avg_mean_per_month\n",
    "    year_stats[year] = (\n",
    "        veloc_means_arr,\n",
    "        veloc_stds_arr,\n",
    "        consecutive_modularity_averages,\n",
    "        avg_std_per_month,\n",
    "        avg_mean_per_month\n",
    "    )\n",
    "\n",
    "# After the loop, create a DataFrame\n",
    "stats_df = pd.DataFrame([\n",
    "    {\n",
    "        'year': year,\n",
    "        'veloc_means_arr': veloc_means_arr,\n",
    "        'veloc_stds_arr': veloc_stds_arr,\n",
    "        'consecutive_modularity_averages': mod_avgs,\n",
    "        'sim_avg_std_per_month': avg_std_per_month,\n",
    "        'sim_avg_mean_per_month': avg_mean_per_month\n",
    "    }\n",
    "    for year, (veloc_means_arr, veloc_stds_arr, mod_avgs, avg_std_per_month, avg_mean_per_month) in year_stats.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2297a589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>veloc_means_arr</th>\n",
       "      <th>veloc_stds_arr</th>\n",
       "      <th>consecutive_modularity_averages</th>\n",
       "      <th>sim_avg_std_per_month</th>\n",
       "      <th>sim_avg_mean_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>[0.051214008463286664, 0.05491317332766376, 0....</td>\n",
       "      <td>[0.05299022692465565, 0.0890761021085431, 0.07...</td>\n",
       "      <td>[0.5680653341085709, 0.5783983258293317, 0.569...</td>\n",
       "      <td>{'January': 0.05438617324026037, 'February': 0...</td>\n",
       "      <td>{'January': 0.01591008195557077, 'February': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>[0.04648863740507882, 0.04981199329265121, 0.0...</td>\n",
       "      <td>[0.05207777475178581, 0.05488856551853223, 0.0...</td>\n",
       "      <td>[0.5111162670097047, 0.5347026476729275, 0.551...</td>\n",
       "      <td>{'January': 0.06722109384721667, 'February': 0...</td>\n",
       "      <td>{'January': 0.024296180851497488, 'February': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>[0.04632057040232594, 0.04101189044380686, 0.0...</td>\n",
       "      <td>[0.03383944252611081, 0.02733676694251247, 0.0...</td>\n",
       "      <td>[0.51963245106091, 0.4870908112851826, 0.47975...</td>\n",
       "      <td>{'January': 0.06090538976340603, 'February': 0...</td>\n",
       "      <td>{'January': 0.020997684324814293, 'February': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>[0.03419731597636642, 0.03098708858310372, 0.0...</td>\n",
       "      <td>[0.0330341457502581, 0.02991915562206083, 0.04...</td>\n",
       "      <td>[0.5112193727677552, 0.5272539271862956, 0.530...</td>\n",
       "      <td>{'January': 0.06033276184962287, 'February': 0...</td>\n",
       "      <td>{'January': 0.020772162064979664, 'February': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>[0.039197716300539656, 0.04606048233657261, 0....</td>\n",
       "      <td>[0.028935671284474378, 0.03648860027168035, 0....</td>\n",
       "      <td>[0.5118907310648402, 0.5256815905362684, 0.542...</td>\n",
       "      <td>{'January': 0.05742891722244035, 'February': 0...</td>\n",
       "      <td>{'January': 0.018737144726381, 'February': 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                    veloc_means_arr  \\\n",
       "0  2018  [0.051214008463286664, 0.05491317332766376, 0....   \n",
       "1  2019  [0.04648863740507882, 0.04981199329265121, 0.0...   \n",
       "2  2020  [0.04632057040232594, 0.04101189044380686, 0.0...   \n",
       "3  2021  [0.03419731597636642, 0.03098708858310372, 0.0...   \n",
       "4  2022  [0.039197716300539656, 0.04606048233657261, 0....   \n",
       "\n",
       "                                      veloc_stds_arr  \\\n",
       "0  [0.05299022692465565, 0.0890761021085431, 0.07...   \n",
       "1  [0.05207777475178581, 0.05488856551853223, 0.0...   \n",
       "2  [0.03383944252611081, 0.02733676694251247, 0.0...   \n",
       "3  [0.0330341457502581, 0.02991915562206083, 0.04...   \n",
       "4  [0.028935671284474378, 0.03648860027168035, 0....   \n",
       "\n",
       "                     consecutive_modularity_averages  \\\n",
       "0  [0.5680653341085709, 0.5783983258293317, 0.569...   \n",
       "1  [0.5111162670097047, 0.5347026476729275, 0.551...   \n",
       "2  [0.51963245106091, 0.4870908112851826, 0.47975...   \n",
       "3  [0.5112193727677552, 0.5272539271862956, 0.530...   \n",
       "4  [0.5118907310648402, 0.5256815905362684, 0.542...   \n",
       "\n",
       "                               sim_avg_std_per_month  \\\n",
       "0  {'January': 0.05438617324026037, 'February': 0...   \n",
       "1  {'January': 0.06722109384721667, 'February': 0...   \n",
       "2  {'January': 0.06090538976340603, 'February': 0...   \n",
       "3  {'January': 0.06033276184962287, 'February': 0...   \n",
       "4  {'January': 0.05742891722244035, 'February': 0...   \n",
       "\n",
       "                              sim_avg_mean_per_month  \n",
       "0  {'January': 0.01591008195557077, 'February': 0...  \n",
       "1  {'January': 0.024296180851497488, 'February': ...  \n",
       "2  {'January': 0.020997684324814293, 'February': ...  \n",
       "3  {'January': 0.020772162064979664, 'February': ...  \n",
       "4  {'January': 0.018737144726381, 'February': 0.0...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016c2c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stats_df from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "stats_checkpoint_path = \"stats_checkpoint.parquet\"\n",
    "\n",
    "# load data from checkpoint or save\n",
    "if os.path.exists(stats_checkpoint_path):\n",
    "    print(\"Loading stats_df from checkpoint...\")\n",
    "    stats_df = pd.read_parquet(stats_checkpoint_path)\n",
    "else:\n",
    "    print(\"Saving stats_df to checkpoint...\")\n",
    "    stats_df.to_parquet(stats_checkpoint_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
